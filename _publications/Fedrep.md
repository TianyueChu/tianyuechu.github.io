---
title: "Securing Federated Sensitive Topic Classification against Poisoning Attacks"
collection: publications
category: conferences
permalink: /publication/2023-02-27-https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s112_paper.pdf
excerpt: 'We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing GDPR-sensitive content related to categories such as health, sexual preference, political beliefs, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers,it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.'
date: 2023-02-27
venue: '30th Annual Network and Distributed System Security Symposium(NDSS)'
slidesurl: #'http://academicpages.github.io/files/slides3.pdf'
paperurl: #'http://academicpages.github.io/files/paper3.pdf'
citation: 'Chu, Tianyue, et al. &quot;Securing Federated Sensitive Topic Classification against Poisoning Attacks.&quot; <i>30th Annual Network and Distributed System Security Symposium, NDSS 2023</i>. San Diego, California, USA, February 27 - March 3, 2023.'
---
We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing GDPR-sensitive content related to categories such as health, sexual preference, political beliefs, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers,it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.

