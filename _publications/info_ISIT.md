---
title: "Information-Theoretical Bounds on Privacy Leakage in Pruned Federated Learning"
collection: publications
category: workshops
permalink: 'https://sites.google.com/view/it-tml2024/schedule?authuser=0'
excerpt: 'In this paper, we investigate for the first time the privacy impact of model pruning in FL. We establish information-theoretic upper bounds on the information leakage from pruned FL and we experimentally validate them under state-of-the-art privacy attacks across different FL pruning schemes. This evaluation provides valuable insights into the choices and parameters that can affect the privacy protection provided by pruning.'
date: 2024-07-07
venue: 'ISIT 2024 Workshop on Information-Theoretic Methods for Trustworthy Machine Learning'
slidesurl: #'http://tianyuechu.github.io/files/slides3.pdf'
paperurl: #'http://tianyuechu.github.io/files/paper3.pdf'
citation: #'Chu, Tianyue, et al. &quot;Strengthening Privacy in Robust Federated Learning through Secure Aggregation.&quot; <i>Workshop on AI Systems with Confidential Computing (AISCC) in conjunction with NDSS</i>. San Diego, California, USA, February 26, 2024.'
---
In this paper, we investigate for the first time the privacy impact of model pruning in FL. We establish information-theoretic upper bounds on the information leakage from pruned FL and we experimentally validate them under state-of-the-art privacy attacks across different FL pruning schemes. This evaluation provides valuable insights into the choices and parameters that can affect the privacy protection provided by pruning.'
