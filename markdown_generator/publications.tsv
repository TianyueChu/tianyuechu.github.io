pub_date	title	venue	excerpt	citation	url_slug	paper_url	slides_url
2024-11-02	PriPrune: Quantifying and Preserving Privacy in Pruned Federated Learning	ACM Transactions on Modeling and Performance Evaluation of Computing Systems	In this paper, we first characterize the privacy offered by pruning. We establish information-theoretic upper bounds on the information leakage from pruned FL and we experimentally validate them under state-of-the-art privacy attacks across different FL pruning schemes. Second, we introduce PriPruneś a privacy-aware algorithm for pruning in FL. PriPrune uses defense pruning masks, which can be applied locally after any pruning algorithm, and adapts the defense pruning rate to jointly optimize privacy and accuracy. Another key idea in the design of PriPrune is Pseudo-Pruning: it undergoes defense pruning within the local model and only sends the pruned model to the server; while the weights pruned out by defense mask are withheld locally for future local training rather than being removed.	Tianyue, Chu. (2024). "PriPrune: Quantifying and Preserving Privacy in Pruned Federated Learning." <i>ACM Transactions on Modeling and Performance Evaluation of Computing Systems</i>. 1(1).	https://dl.acm.org/doi/abs/10.1145/3702241	http://academicpages.github.io/files/paper1.pdf	http://academicpages.github.io/files/slides1.pdf
2024-06-13	FedQV: Leveraging Quadratic Voting in Federated Learning	2024 ACM SIGMETRICS/IFIP PERFORMANCE	 In this paper, we propose FEDQV, a novel aggregation algorithm built upon the quadratic voting scheme, recently proposed as a better alternative to 1p1v-based elections. Our theoretical analysis establishes that FEDQV is a truthful mechanism in which bidding according to one’s true valuation is a dominant strategy that achieves a convergence rate that matches those of state-of-the-art methods. Furthermore, our empirical analysis using multiple real-world datasets validates the superior performance of FEDQV against poisoning attacks. It also shows that combining FEDQV with unequal voting “budgets” according to a reputation score increases its performance benefits even further. Finally, we show that FEDQV can be easily combined with Byzantine-robust privacy-preserving mechanisms to enhance its robustness against both poisoning and privacy attacks.	Tianyue, Chu. (2024). "FEDQV: Leveraging Quadratic Voting In Federated Learning." <i>ACM SIGMETRICS 2024 </i>.	https://dl.acm.org/doi/abs/10.1145/3656006	http://academicpages.github.io/files/paper2.pdf	http://academicpages.github.io/files/slides2.pdf
2023-02-27	Securing Federated Sensitive Topic Classification against Poisoning Attacks	30th Annual Network and Distributed System Security Symposium, NDSS 2023	We present a Federated Learning (FL) based solution for building a distributed classifier capable of detecting URLs containing GDPR-sensitive content related to categories such as health, sexual preference, political beliefs, etc. Although such a classifier addresses the limitations of previous offline/centralised classifiers,it is still vulnerable to poisoning attacks from malicious users that may attempt to reduce the accuracy for benign users by disseminating faulty model updates. To guard against this, we develop a robust aggregation scheme based on subjective logic and residual-based attack detection. Employing a combination of theoretical analysis, trace-driven simulation, as well as experimental validation with a prototype and real users, we show that our classifier can detect sensitive content with high accuracy, learn new labels fast, and remain robust in view of poisoning attacks from malicious users, as well as imperfect input from non-malicious ones.	Tianyue Chu(2023). "Securing Federated Sensitive Topic Classification against Poisoning Attacks." <i>30th Annual Network and Distributed System Security Symposium, NDSS 2023</i>. San Diego, California, USA, February 27 - March 3, 2023.	https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s112_paper.pdf	http://academicpages.github.io/files/paper3.pdf	http://academicpages.github.io/files/slides3.pdf